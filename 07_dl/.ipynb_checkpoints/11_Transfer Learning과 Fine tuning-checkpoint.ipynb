{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZEiUymWcbfRZ"
   },
   "source": [
    "# Pretrained Model\n",
    "\n",
    "- 다른 목적을 위해 미리 학습된 모델.\n",
    "- Pretrained model을 현재 해결하려는 문제에 이용한다.\n",
    "- 대부분 내가 만들려는 네트워크 모델에 pretrained model을 포함시켜 사용한다.\n",
    "    - 이런 방식을 Transfer Learning (전이 학습)이라고 한다.\n",
    "    - 보통 Feature Extractor block을 재사용한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AFtMH4PMWGCa"
   },
   "source": [
    "## Pytorch에서 제공하는 Pretrained Model \n",
    "- 분야별 라이브러리에서 제공\n",
    "    - torchvision: https://pytorch.org/vision/stable/models.html\n",
    "- torch hub 를 이용해 모델과 학습된 parameter를 사용할 수 있다.\n",
    "    - https://pytorch.org/hub/\n",
    "- 이외에도 많은 모델과 학습된 paramter가 인터넷상에 공개되 있다.    \n",
    "    - 딥러닝 모델기반 application을 개발 할 때는 대부분 Transfer Learning을 한다.  \n",
    "    - 다양한 분야에서 연구된 많은 딥러닝 모델들이 구현되어 공개 되어 있으며 학습된 Parameter들도 제공되고 있다.  \n",
    "    - [paperswithcode](https://paperswithcode.com/)에서 State Of The Art(SOTA) 논문들과 그 구현된 모델을 확인할 수 있다. \n",
    "    \n",
    ">  **State Of The Art(SOTA)**: 특정 시점에 특정 분야에서 가장 성능이 좋은 모델을 말한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RRSB293RWGCa"
   },
   "source": [
    "## VGGNet Pretrained 모델을 이용해 이미지 분류\n",
    "\n",
    "- Output으로 1000개의 class에 대한 확률을 출력한다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1000개의 class 목록\n",
    "!pip install wget\n",
    "import wget\n",
    "url = 'https://gist.github.com/yrevar/942d3a0ac09ec9e5eb3a/raw/238f720ff059c1f82f368259d1ca4ffa5dd8f9f5/imagenet1000_clsidx_to_labels.txt'\n",
    "imagenet_filepath = wget.download(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dqmJxjjcWGCg"
   },
   "outputs": [],
   "source": [
    "# 추론할 이미지 다운로드\n",
    "import requests\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "\n",
    "img_url = 'https://upload.wikimedia.org/wikipedia/commons/thumb/2/25/Common_goldfish.JPG/800px-Common_goldfish.JPG'\n",
    "# img_url = 'https://cdn.download.ams.birds.cornell.edu/api/v1/asset/169231441/1800'\n",
    "# img_url = 'https://blogs.ifas.ufl.edu/news/files/2021/10/anole-FB.jpg'\n",
    "res = requests.get(img_url)\n",
    "test_img = Image.open(BytesIO(res.content))\n",
    "test_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H_sLmJGHWGCi"
   },
   "source": [
    "# Transfer learning (전이학습)\n",
    "- 사전에 학습된 신경망의 구조와 파라미터를 재사용해서 새로운 모델(우리가 만드는 모델)의 시작점으로 삼고 해결하려는 문제를 위해 다시 학습시킨다.\n",
    "- 전이 학습을 통해 다음을 해결할 수 있다.\n",
    "    1. 데이터 부족문제\n",
    "        - 딥러닝은 대용량의 학습데이터가 필요하다.\n",
    "        - 충분한 데이터를 수집하는 것은 항상 어렵다.\n",
    "    2. 과다한 계산량\n",
    "        - 신경망 학습에는 엄청난 양의 계산 자원이 필요하다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cj9RRN6QbfRR"
   },
   "source": [
    "![transfer_learning01](figures/09_transfer_01.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5dXETWizbfRS"
   },
   "source": [
    "- 미리 학습된(pre-trained) Model을 이용하여 모델을 구성한 뒤 현재 하려는 예측 문제를 해결한다.\n",
    "- 보통 Pretrained Model에서 Feature Extraction 부분을 사용한다.\n",
    "    - Computer Vision 문제의 경우 Bottom 쪽의 Convolution Layer(Feature Extractor)들은 이미지에 나타나는 일반적인 특성을 추출하므로 **다른 대상을 가지고 학습했다고 하더라도 재사용할 수 있다.**\n",
    "    - Top 부분 Layer 부분은 특히 출력 Layer의 경우 대상 데이터셋의 목적에 맞게 변경 해야 하므로 재사용할 수 없다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZnS6S0QPbfRT"
   },
   "source": [
    "![transfer_learning02](figures/09_transfer_02.png)\n",
    "\n",
    "> **Frozon**: Training시 parameter가 update 되지 않도록 하는 것을 말한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NRLhG6D8bfRb"
   },
   "source": [
    "### Feature extraction 재사용\n",
    "- Pretrained Model에서 Feature Extractor 만 가져오고 추론기(Fully connected layer)만 새로 정의한 뒤 그 둘을 합쳐서 모델을 만든다.\n",
    "- 학습시 직접 구성한 추론기만 학습되도록 한다.\n",
    "    - Feature Extractor는 추론을 위한 Feature 추출을 하는 역할만 하고 그 parameter(weight)가 학습되지 않도록 한다.\n",
    "- 모델/레이어의 parameter trainable 여부 속성 변경\n",
    "    - model/layer 의 `parameters()` 메소드를 이용해 weight와 bias를 조회한 뒤 `requires_grad` 속성을 `False`로 변경한다.\n",
    "        \n",
    "#### Backbone, Base network\n",
    "전체 네트워크에서 Feature Extraction의 역할을 담당하는 부분을 backbone/base network라고 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "miqV_0WSbfRm"
   },
   "source": [
    "## Fine-tuning(미세조정)\n",
    "- Transfer Learning을 위한 Pretrained 모델을 내가 학습시켜야 하는 데이터셋(Custom Dataset)으로 **재학습**시키는 것을 fine tunning 이라고 한다.\n",
    "- 주어진 문제에 더 적합하도록 Feature Extractor의 가중치들도 조정 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "py7c3rmmbfRm"
   },
   "source": [
    "### Fine tuning 전략\n",
    "![transfer02](figures/09_transfer_03.png)\n",
    "\n",
    "- **세 전략 모두 추론기는 trainable로 한다.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4wtxXsYUbfRn"
   },
   "source": [
    "**<font size='5'>1. 전체 모델을 전부 학습시킨다.(1번)</font>**    \n",
    "- Pretrained 모델의 weight는 Feature extraction 의 초기 weight 역할을 한다.\n",
    "- **Train dataset의 양이 많고** Pretrained 모델이 학습했던 dataset과 Custom dataset의 class간의 유사성이 **낮은 경우** 적용.\n",
    "- 학습에 시간이 많이 걸린다.\n",
    "    \n",
    "    \n",
    "**<font size='5'>2. Pretrained 모델 Bottom layer들(Input과 가까운 Layer들)은 고정시키고 Top layer의 일부를 재학습시킨다.(2번)</font>**     \n",
    "- **Train dataset의 양이 많고** Pretrained 모델이 학습했던 dataset과 Custom dataset의 class간의 유사성이 **높은 경우** 적용.\n",
    "- **Train dataset의 양이 적고** Pretained 모델이 학습했던 dataset과 custom dataset의 class간의 유사성이 **낮은 경우** 적용\n",
    "    \n",
    "    \n",
    "**<font size='5'>3. Pretrained 모델 전체를 고정시키고 classifier layer들만 학습시킨다.(3번)</font>**      \n",
    "- **Train dataset의 양이 적고** Pretrained 모델이 학습했던 dataset과 Custom dataset의 class간의 유사성이 **높은 경우** 적용.\n",
    "  \n",
    "  \n",
    "> **Custom dataset:** 내가 학습시키고자 하는 dataset \n",
    "> 1번 2번 전략을 Fine tuning 이라고 한다.\n",
    "\n",
    "![fine tuning](figures/09_finetuning.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models, datasets, transforms\n",
    "from torchinfo import summary\n",
    "\n",
    "from module.train import fit\n",
    "from module.utils import plot_fit_result\n",
    "\n",
    "import os\n",
    "from zipfile import ZipFile\n",
    "!pip install gdown -U\n",
    "import gdown\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download\n",
    "url = 'https://drive.google.com/uc?id=1YIxDL0XJhhAMdScdRUfDgccAqyCw5-ZV'\n",
    "path = r'data/cats_and_dogs_small.zip'\n",
    "gdown.download(url, path, quiet=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9x8yDSiBWGCm"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k8EqrXFlWGCn"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "anaconda-cloud": {},
  "colab": {
   "collapsed_sections": [
    "ZEiUymWcbfRZ"
   ],
   "provenance": []
  },
  "gpuClass": "standard",
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "551.4px",
    "left": "1166px",
    "right": "20px",
    "top": "120px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
