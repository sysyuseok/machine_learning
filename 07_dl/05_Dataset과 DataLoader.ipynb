{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Dataset 과 DataLoader\n",
    "\n",
    "- 딥러닝 모델을 학습시키고 평가할때 사용할 데이터를 제공하기 위한 객체\n",
    "- **torch.utils.data.Dataset**\n",
    "    - input/output dataset을 저장한다.\n",
    "    - subscriptable, iterable 타입. \n",
    "    > subscriptable타입: indexing을 이용해 원소 조회가 가능한 타입)\n",
    "    \n",
    "- **torch.utils.data.DataLoader**\n",
    "    - Dataset의 데이터를 제공하는 Iterable 객체.\n",
    "    - Dataset이 가지고 있는 데이터를 어떻게 제공할 지 설정한다.\n",
    "        - data augmentation, batch size 등을 설정한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Built-in Dataset\n",
    "\n",
    "- 파이토치는 분야별 공개 데이터셋을 종류별로 torchvision, torchtext, torchaudio 모듈을 통해 제공한다.\n",
    "- 모든 built-in dataset은 [`torch.utils.data.Datase`](https://pytorch.org/docs/stable/data.html#torch.utils.data.Dataset)의 하위클래스로 구현되있다.\n",
    "    - [computer vision dataset](https://pytorch.org/vision/stable/datasets.html)\n",
    "    - [text dataset](https://pytorch.org/text/stable/datasets.html)\n",
    "    - [audio dataset](https://pytorch.org/audio/stable/datasets.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image  Built-in dataset Loading\n",
    "torchvision 모듈을 통해 다양한 오픈소스 이미지 데이터셋을 loading할 수 있는 Dataset 클래스를 제공한다.\n",
    "\n",
    "- 각 Dataset 클래스의 주요 매개변수\n",
    "    - **root**: str\n",
    "        - Raw data를 저장할 디렉토리 경로\n",
    "    - **train**: bool\n",
    "        - True일경우 Train set을 False일 경우 Test set을 load\n",
    "    - **download**: bool\n",
    "        - True이면 root에 지정된 경로에 raw 데이터를 인터셋에서 download할지 여부. 이미 저장되 있는 경우 download하지 않는다.\n",
    "    - **transform**: function\n",
    "        - Loading한 이미지를 변환하는 function.\n",
    "            - Normalization이나 data Agumentation 처리를 한다.\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO\n",
    "\n",
    "- CIFAR10 Built-in dataset 을 LOADING 후 다음을 확인하시오.\n",
    "    1. Dataset loading\n",
    "    1. train, test dataset의 데이터 개수\n",
    "    1. train set 과 test set의 input data의  shape\n",
    "    1. train set 과 test set의 output data의  shape\n",
    "    1. class index - class name\n",
    "    1. train set의 이미지 5장을 출력. label의 이름을 title로 출력.\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### transform 매개변수를 이용한 정규화\n",
    "\n",
    "- Feature scaling과 동일한 목적으로 image의 전체 pixel의 값들이 유사한 scale을 가지도록 처리한다.\n",
    "- transform 매개변수에 전처리 함수를 넣으면 데이터에 대한 전처리를 할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-24T10:48:13.851346Z",
     "start_time": "2023-05-24T10:48:13.831036Z"
    }
   },
   "source": [
    "#### ToTensor\n",
    " -  PIL Image나 NumPy ndarray 를 FloatTensor 로 변환하고, 이미지의 픽셀의 크기(intensity) 값을 \\[0., 1.\\] 범위로 비례하여 조정한다.\n",
    " - https://pytorch.org/vision/stable/transforms.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### transform.Normalize\n",
    "- 채널별로 지정한 평균을 뺀 뒤 지정한 표준편차로 나워서 정규화를 진행한다.\n",
    "- ToTensor()로 변환된 데이터를 받아서 추가 변환\n",
    "        - 여려 변환을 할 경우 `torchvision.transforms.Compose` 클래스를 이용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataLoader 생성\n",
    "\n",
    "- DataLoader\n",
    "    - 모델이 학습하거나 추론할 때 Dataset의 데이터를 모델에 제공해준다. (feeding)\n",
    "    - initalizer속성\n",
    "        - dataset: 값을 제공하는 Dataset 타입 객체\n",
    "        - batch_size: 한번에 값을 제공할 batch 크기\n",
    "        - shuffle: 에폭마다 데이터셋을 섞을 지 여부 (default: False)\n",
    "        - drop_last: 마지막 배치의 데이터개수가 batch_size 설정보다 적을 경우 모델에 제공하지 않는다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Dataset 구현\n",
    "\n",
    "1. `torch.utils.data.DataSet` 클래스를 상속한 클래스를 정의한다.\n",
    "2. `__init__(self, ...)` \n",
    "    - DataSet객체 생성시 필요한 설정들을 초기화 한다. \n",
    "    - ex) Data저장 경로, transform 설정 여부 등\n",
    "3. `__len__(self)`\n",
    "    - 총 데이터 수를 반환하도록 구현한다.\n",
    "    - DataLoader가 Batch 생성할 때 사용한다.\n",
    "4. `__getitem__(self, index)`\n",
    "    - index의 Data point를 반환한다.\n",
    "    - input(X), output(y) 를 튜플로 반환한다.\n",
    "    - transform이 있을 경우 변환처리한 input을 반환한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OxfordPet Dataset 생성\n",
    "- https://www.robots.ox.ac.uk/~vgg/data/pets/\n",
    "- 개,고양이 37가지 품종\n",
    "- 품종별로 200장 정도씩 구성됨. (품종별로 이미지 개수는 다르다)\n",
    "\n",
    "- 목표\n",
    "    - train: 70%, validation: 20%, test: 10%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### index_to_class, class_to_index 생성\n",
    "- index_to_class : class들을 가지는 리스트. index(0, 1, ..)로 class 조회\n",
    "- class_to_index : key: 클래스이름, value: index -> class이름 넣으면 index 반환\n",
    "- 파일명이 class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset을 이용해 CSV파일에 저장된 데이터셋 로딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## torchvision.datasets.ImageFolder 이용\n",
    "- 저장장치에 파일로 저장된 image들을 쉽게 로딩할 수 있도록 한다.\n",
    "- train/validation/test 데이터셋을 저장하는 디렉토리에 class 별로 디렉토리를 만들고 이미지를 저장한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install gdown --upgrade\n",
    "import os\n",
    "from zipfile import ZipFile\n",
    "import gdown\n",
    "def down_extract():\n",
    "    os.makedirs('data', exist_ok=True)\n",
    "    url = 'https://drive.google.com/uc?id=1YIxDL0XJhhAMdScdRUfDgccAqyCw5-ZV'\n",
    "    fname = 'data/cats_and_dogs_small.zip'\n",
    "\n",
    "    gdown.download(url, fname, quiet=False)\n",
    "    \n",
    "    #zipfile모듈: Zip 압축파일을 다루는 모듈(압축하기, 풀기)\n",
    "    from zipfile import ZipFile\n",
    "    # 압축풀기: ZipFile(압축파일경로).extractall(풀경로) # 디렉토리 없으면 생성해 준다.\n",
    "    with ZipFile(fname) as zipFile:\n",
    "        zipFile.extractall(os.path.join('data','cats_and_dogs_small'))\n",
    "        \n",
    "down_extract()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "455.111px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
